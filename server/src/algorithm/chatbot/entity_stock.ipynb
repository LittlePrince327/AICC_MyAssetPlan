{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c35204",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Chatbot_Entity_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mChatbot_Entity_date\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01med\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Chatbot_Entity_date'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "import pytz\n",
    "import Chatbot_Entity_date as ed\n",
    "\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from konlpy.tag import Hannanum\n",
    "from pykospacing import Spacing\n",
    "from konlpy.tag import Okt, Kkma\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()\n",
    "spacing = Spacing()\n",
    "hannanum = Hannanum()\n",
    "kst = pytz.timezone('Asia/Seoul') # 한국 표준시 (KST)\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('chunkers/maxent_ne_chunker')\n",
    "except LookupError:\n",
    "    nltk.download('maxent_ne_chunker')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/words')\n",
    "except LookupError:\n",
    "    nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d836938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Komoran 형태소 분석기 사용\n",
    "komoran = Komoran()\n",
    "\n",
    "def extract_stock_entities(text):\n",
    "    \"\"\"주어진 텍스트에서 주식 관련 엔티티를 추출하는 통합 함수입니다.\"\"\"\n",
    "    \n",
    "    # 주식 관련 패턴 정의\n",
    "    patterns1 = {\n",
    "        \"주가\": r\"주가|주식|종가\",\n",
    "        \"증시\": r\"증시\",\n",
    "        \"삼성전자\": r\"삼성전자|삼성|삼전|samsung\",\n",
    "        \"애플\": r\"애플|apple\",\n",
    "        \"비트코인\": r\"비트코인|bitcoin|비트|코인|coin\",\n",
    "        \"PER\": r\"PER|per|주가수익비율|Price Earning Ratio\",\n",
    "        \"PBR\": r\"PBR|pbr|주가순자산비율|Price Book-value Ratio\",\n",
    "        \"ROE\": r\"ROE|roe|자기자본이익률|Return on Equity\",\n",
    "        \"MC\": r\"MC|mc|시가총액|총액|시총|Market Cap\",\n",
    "        \"경제지표\":r\"경제지표|국내총생산|GDP|기준금리|IR|수입물가지수|IPI|생산자물가지수|PPI|소비자물가지수|CPI|외환보유액\"\n",
    "    }\n",
    "    print(\"patterns1 defined:\", patterns1)\n",
    "\n",
    "    # 주식 관련 예측 및 변동성 패턴 정의 (동사 포함)\n",
    "    patterns2 = {\n",
    "        \"예상\": r\"예상|예측|전망|앞으로\",\n",
    "        \"가격\": r\"가격|값\"\n",
    "    }\n",
    "    print(\"patterns2 defined:\", patterns2)\n",
    "\n",
    "    # 패턴 통합\n",
    "    combined_patterns = {**patterns1, **patterns2}\n",
    "    print(\"combined_patterns defined:\", combined_patterns)\n",
    "\n",
    "    # 텍스트에서 패턴에 맞는 주요 키워드 추출\n",
    "    def extract_main_keyword(text, pattern):\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            print(f\"Matched keyword in text '{text}' with pattern '{pattern}': {match.group(0)}\")\n",
    "            return match.group(0)  # 매칭된 주요 키워드 반환\n",
    "        return None  # 매칭되지 않으면 None 반환\n",
    "\n",
    "    def clean_text(text):\n",
    "        # Komoran으로 형태소 분석을 수행\n",
    "        token_pos = komoran.pos(text)\n",
    "        cleaned_tokens = [word for word, pos in token_pos if not pos.startswith('J')]\n",
    "        cleaned_text = ''.join(cleaned_tokens)\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    # 사용자 정의 spaCy 파이프라인 컴포넌트\n",
    "    @spacy.Language.component(\"custom_stock_entity_adder\")\n",
    "    def custom_stock_entity_adder(doc):\n",
    "        new_ents = []\n",
    "        print(\"Processing doc:\", doc)\n",
    "\n",
    "        for token in doc:\n",
    "            print(\"Processing token:\", token.text)\n",
    "            # 형태소 분석을 통해 명사와 동사/형용사 추출\n",
    "            token_pos = komoran.pos(token.text)\n",
    "            print(f\"Token POS: {token_pos}\")\n",
    "            \n",
    "            # 품사별로 나눠서 명사 및 동사 추출\n",
    "            noun_phrase = ''.join([word for word, tag in token_pos if tag in ['NNG', 'NNP', 'SL']])  # 명사\n",
    "            verb_phrase = ''.join([word for word, tag in token_pos if tag in ['VV', 'VA']])  # 동사/형용사\n",
    "            print(f\"Noun phrase: {noun_phrase}, Verb phrase: {verb_phrase}\")\n",
    "\n",
    "            # 형태소 분석 결과와 원래 텍스트 보정\n",
    "            noun_phrase_cleaned = clean_text(noun_phrase)  # 형태소 분석된 명사에서 조사를 제거\n",
    "            original_text_cleaned = clean_text(token.text)  # 원래 텍스트에서 조사를 제거\n",
    "\n",
    "            found = False  # 해당 단어가 패턴과 매칭되는지 확인\n",
    "            for label, pattern in combined_patterns.items():\n",
    "                if noun_phrase_cleaned and len(noun_phrase_cleaned) > 1:  # 명사가 있으면\n",
    "                    main_keyword = extract_main_keyword(noun_phrase_cleaned, pattern)\n",
    "                    if main_keyword:\n",
    "                        found = True\n",
    "                        new_ent = Span(doc, token.i, token.i + 1, label=label)\n",
    "                        new_ent._.set(\"cleaned_text\", noun_phrase_cleaned)\n",
    "                        new_ents.append(new_ent)\n",
    "                        print(f\"New entity added: {new_ent}, Label: {label}\")\n",
    "                        break\n",
    "\n",
    "                if verb_phrase:  # 동사/형용사가 있으면\n",
    "                    main_keyword = extract_main_keyword(verb_phrase, pattern)\n",
    "                    if main_keyword:\n",
    "                        found = True\n",
    "                        new_ent = Span(doc, token.i, token.i + 1, label=label)\n",
    "                        new_ent._.set(\"cleaned_text\", verb_phrase)\n",
    "                        new_ents.append(new_ent)\n",
    "                        print(f\"New entity added: {new_ent}, Label: {label}\")\n",
    "                        break\n",
    "\n",
    "            if not found:\n",
    "                # 원래 텍스트에 기반해 패턴 매칭 시도\n",
    "                main_keyword = extract_main_keyword(original_text_cleaned, pattern)\n",
    "                if main_keyword:\n",
    "                    new_ent = Span(doc, token.i, token.i + 1, label=label)\n",
    "                    new_ent._.set(\"cleaned_text\", original_text_cleaned)\n",
    "                    new_ents.append(new_ent)\n",
    "                    print(f\"New entity added based on original text: {new_ent}, Label: {label}\")\n",
    "                    break\n",
    "\n",
    "        # 최종 엔티티 설정\n",
    "        doc.ents = new_ents\n",
    "        print(f\"Final entities in doc: {new_ents}\")\n",
    "\n",
    "        return doc\n",
    "\n",
    "    # spaCy 모델 로드\n",
    "    nlp = spacy.load(\"ko_core_news_sm\")\n",
    "    print(\"spaCy model loaded\")\n",
    "\n",
    "    # 확장 속성 등록\n",
    "    Span.set_extension(\"cleaned_text\", default=None, force=True)\n",
    "    print(\"Span extension 'cleaned_text' set\")\n",
    "\n",
    "    # 기존 파이프라인에서 custom_stock_entity_adder 제거\n",
    "    if \"custom_stock_entity_adder\" in nlp.pipe_names:\n",
    "        nlp.remove_pipe(\"custom_stock_entity_adder\")\n",
    "        print(\"Removed existing 'custom_stock_entity_adder' from pipeline\")\n",
    "\n",
    "    # custom_stock_entity_adder 추가\n",
    "    nlp.add_pipe(\"custom_stock_entity_adder\", after=\"ner\")\n",
    "    print(\"'custom_stock_entity_adder' added to pipeline\")\n",
    "\n",
    "    # 텍스트 처리\n",
    "    doc = nlp(text)\n",
    "    print(f\"Processed text: {text}\")\n",
    "\n",
    "    # 결과 출력\n",
    "    entities = [ent._.get(\"cleaned_text\") for ent in doc.ents] + [ent.label_ for ent in doc.ents]\n",
    "    print(f\"Entities found in text: {entities}\")\n",
    "    return list(set(entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "353e5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 정보: PER, PBR, ROE, MC\n",
    "\n",
    "def stock_information(text):\n",
    "    # 엔터티 추출\n",
    "    entities = extract_stock_entities(text)\n",
    "    \n",
    "    # 엔터티 레이블 추출\n",
    "    entity_labels = []\n",
    "    for _, label in entities:\n",
    "        entity_labels.append(label)\n",
    "    \n",
    "    # 주식 종목 리스트\n",
    "    stock_labels = [\"삼성전자\", \"애플\", \"비트코인\"]\n",
    "\n",
    "    # 사용자가 요청한 주식 종목을 추출\n",
    "    requested_stocks = [stock for stock in stock_labels if stock in entity_labels]\n",
    "\n",
    "    # 주식 정보 엔터티 (PBR, PER, ROE, MC) 리스트\n",
    "    info_labels = [\"PBR\", \"PER\", \"ROE\", \"MC\"]\n",
    "\n",
    "    # 사용자가 요청한 주식 정보 엔터티를 추출\n",
    "    requested_infos = [info for info in info_labels if info in entity_labels]\n",
    "    \n",
    "    # SQL 쿼리 생성 및 답변 생성\n",
    "    if requested_stocks and requested_infos:\n",
    "        # 각 주식 종목과 정보에 따라 쿼리와 답변 생성\n",
    "        stock = requested_stocks[0]  # 하나의 주식 종목만 처리\n",
    "        info = requested_infos[0]  # 하나의 정보만 처리\n",
    "\n",
    "        # SQL 쿼리 생성\n",
    "        date = \"2024-09-01\" # 특정 날짜\n",
    "        query = \"\"\n",
    "        if stock == \"삼성전자\":\n",
    "            if info == \"PBR\":\n",
    "                query = f\"SELECT sc_ss_pbr FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"PER\":\n",
    "                query = f\"SELECT sc_ss_per FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"ROE\":\n",
    "                query = f\"SELECT sc_ss_roe FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"MC\":\n",
    "                query = f\"SELECT sc_ss_mc FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "\n",
    "        elif stock == \"애플\":\n",
    "            if info == \"PBR\":\n",
    "                query = f\"MSELECT sc_ap_pbr FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"PER\":\n",
    "                query = f\"SELECT sc_ap_per FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"ROE\":\n",
    "                query = f\"SELECT sc_ap_roe FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "            elif info == \"MC\":\n",
    "                query = f\"MSELECT sc_ap_mc FROM tb_stock WHERE fd_date = '{date}';\"\n",
    "                return query\n",
    "\n",
    "        elif stock == \"비트코인\":\n",
    "            if info == \"PBR\":\n",
    "                return ''\n",
    "            elif info == \"PER\":\n",
    "                return ''\n",
    "            elif info == \"ROE\":\n",
    "                return ''\n",
    "            elif info == \"MC\":\n",
    "                return ''\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7297c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"삼성전자 주가알려줘\"\n",
    "def stock_create_quary(text):\n",
    "    entity = extract_stock_entities(text)\n",
    "    print(entity)\n",
    "    if \"주가\" in entity:\n",
    "        stock_price_samsung = stock_price(text)\n",
    "        print(stock_price_samsung)\n",
    "stock_create_quary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71362e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 가격: 언제 삼성전자 주식 얼마야?\n",
    "\n",
    "def stock_price(text):\n",
    "    entities = extract_stock_entities(text)\n",
    "    \n",
    "    # 엔터티 레이블 추출\n",
    "    entity_labels = []\n",
    "    for _, label in entities:\n",
    "        entity_labels.append(label)\n",
    "        \n",
    "    # 주식 종목 리스트\n",
    "    stock_labels = [\"삼성전자\", \"애플\", \"비트코인\"]\n",
    "\n",
    "    # 사용자가 요청한 주식 종목을 추출\n",
    "    requested_stocks = [stock for stock in stock_labels if stock in entity_labels]\n",
    "    \n",
    "    # SQL 쿼리 생성\n",
    "    date = \"2024-09-01\" # 특정 날짜\n",
    "    query = \"\"\n",
    "    # \"가격\" 엔터티가 있는지 확인\n",
    "    if \"가격\" in entity_labels:\n",
    "        if \"삼성전자\" in requested_stocks:\n",
    "            return \"SELECT sc_ss_stock FROM tb_stock WHERE sp_date = '{date}'\"\n",
    "        elif \"애플\" in requested_stocks:\n",
    "            return \"SELECT sc_ap_stock FROM tb_stock WHERE sp_date = '{date}'\"\n",
    "        elif \"비트코인\" in requested_stocks:\n",
    "            return \"SELECT sc_coin FROM tb_stock WHERE sp_date = '{date}'\"\n",
    "        else:\n",
    "            return \"해당 정보가 없습니다.\"\n",
    "    else:\n",
    "        return \"다시 질문해주시겠습니까?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba8a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 예상 (주식, 비트코인 가격 예측 페이지 던져주기)\n",
    "\n",
    "def predict_stock(text):\n",
    "    #엔터티 추출\n",
    "    entities = extract_stock_entities(text)\n",
    "    \n",
    "    # 엔터티 레이블 추출\n",
    "    entity_labels = []\n",
    "    for _, label in entities:\n",
    "        entity_labels.append(label)\n",
    "        \n",
    "    # \"예상\" 엔터티가 있는지 확인\n",
    "    if \"예상\" in entity_labels:\n",
    "        return \"주식/비트코인에 대한 예상값은 다음 링크를 참조하세요: https://www.example.com/stock-prediction\"\n",
    "    \n",
    "# 테스트 예제\n",
    "text = \"비트코인과 애플의 다음 달 예상 값을 알고 싶어요.\"\n",
    "print(text)\n",
    "print(predict_stock(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경제지표 (비교 페이지 던져주기)\n",
    "\n",
    "def economic_indicator(text):\n",
    "    # 엔터티 추출\n",
    "    entities = extract_stock_entities(text)\n",
    "    \n",
    "    # 엔터티 레이블 추출\n",
    "    entity_labels = []\n",
    "    for _, label in entities:\n",
    "        entity_labels.append(label)\n",
    "    \n",
    "    # \"경제지표\" 엔티티가 있는지 확인\n",
    "    if \"경제지표\" in entity_labels:\n",
    "        return \"경제지표에 대한 자세한 정보는 다음 링크를 참조하세요: https://www.example.com/economic-indicators\"\n",
    "    \n",
    "# 테스트 예제\n",
    "text = \"다음 달의 경제지표를 알고 싶어요.\"\n",
    "print(economic_indicator(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577e172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
