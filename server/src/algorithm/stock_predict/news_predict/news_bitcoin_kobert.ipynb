{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1724661764248,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"eQUtXUS5HMDX"},"outputs":[],"source":["#!pip install konlpy\n","#!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":14808,"status":"ok","timestamp":1724661782190,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"heZOByPpG--z"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  torch.utils._pytree._register_pytree_node(\n","c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}],"source":["# 라이브러리 불러오기 및 함수화\n","import os\n","import re\n","import shutil\n","import itertools\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.utils import resample\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","import torch\n","from konlpy.tag import Komoran\n","from pykospacing import Spacing\n","import torch.nn.functional as F\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n","from transformers import BertTokenizer, BertModel, ProgressCallback, Trainer, BertForSequenceClassification, TrainingArguments\n","\n","komoran = Komoran()\n","spacing = Spacing()\n","label_encoder = LabelEncoder()\n","\n","# tqdm과 pandas 통합\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3464,"status":"ok","timestamp":1724661842572,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"FcBIq7EOoKFg"},"outputs":[],"source":["# 파일 업로드\n","# uploaded = files.upload()\n","\n","df = pd.read_excel('../../../data/bitcoin_news1.xlsx')\n","\n","# 기본 불용어 불러오기\n","# korean_stopwords_path = 'stopwords-ko.txt'\n","# with open(korean_stopwords_path, encoding='utf8') as f:\n","#     stopwords = f.readlines()\n","# stopwords = [x.strip() for x in stopwords]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1724661842572,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"0_IjlVf2oGYs"},"outputs":[],"source":["# # 텍스트 전처리 함수\n","# def preprocessing(text):\n","#     text = spacing(text)\n","#     text = text.lower()\n","#     text = re.sub(r'[^\\w\\s]', '', text)\n","#     return text\n","\n","# # komoran토큰화 &불용어 처리 함수\n","# def remove_stopwords(text, stopwords):\n","#     tokens = []\n","#     morphs = komoran.morphs(text)\n","#     for token in morphs:\n","#         if token not in stopwords:\n","#             tokens.append(token)\n","#     return tokens\n","\n","# # 텍스트 전처리 및 토큰화, 불용어 처리\n","# cleaned_data = []\n","# for i in tqdm(range(len(df))):\n","#     feature_text = df.loc[i, 'summary_content']\n","#     processed_text = preprocessing(feature_text)\n","#     cleaned_text = remove_stopwords(processed_text, stopwords)\n","#     cleaned_data.append(cleaned_text)\n","# df['cleaned'] = cleaned_data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1724661844473,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"7SnQhItRbWHy","outputId":"a8433bc5-821b-4eb3-bcf0-1276d0d517ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["호재    6100\n","악재    5798\n","Name: Outcome, dtype: int64\n"]}],"source":["# 클래스별로 데이터 분리\n","df_positive = df[df['Outcome'] == '악재'] # 0\n","df_negative = df[df['Outcome'] == '호재'] # 1\n","\n","# 최소 클래스의 샘플 수 확인\n","min_class_count = min(len(df_positive), len(df_negative))\n","\n","# 다운샘플링 적용\n","df_positive_downsampled = resample(df_positive,\n","                                   replace=True,                                # 샘플을 복원하지 않고\n","                                   n_samples=int(min_class_count*2.30),         # 최소 클래스의 개수로 맞추기\n","                                   random_state=42)                             # 재현성을 위해 random_state 사용\n","\n","df_negative_downsampled = resample(df_negative,\n","                                   replace=True,\n","                                   n_samples=int(min_class_count*2.42),\n","                                   random_state=42)\n","\n","df_balanced = pd.concat([df_positive_downsampled, df_negative_downsampled])     # 다운샘플링된 데이터 결합\n","df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)         # 데이터 셔플\n","print(df['Outcome'].value_counts())                                    # 결과 확인"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367,"referenced_widgets":["20a0a0c7e9434b96be783175d55d6a49","dcc5832d35694f6bbd2758d3a701f6c0","4ba4e2faeff44cffbefbbbeb0f53752f","20d19704dfd5498f9b84becb4fb84435","11a3d0c57ac74fc788e3e65b6dc1e782","6de4c8c208a5433c8e7fe8be4d3195a5","eddbc876d094424581a41dd333b984aa","dd3e3b636ac64743978083e04db057cc","868a7230127743f8b19825f5dab23bc9","d6a47693e8384857aab13e5d4ab05b0d","6679ad84b133433097b8204ae9bbaba9","cf14aaf71e0143fc8faf3b6e0e733876","a87efcdaafe847398d8246638fc06db2","767babe894dc4b96b3ab34a7e7a7390d","1273e99a6766423ba55104faad8d40eb","fba7a58fbd1f4c04b71adbd31526e731","5320d94d31bf49978cd43e9df815ccf7","8a81ddbf107e480d9a8fbe6a2bfddf67","ce749d0b4c05449b932828e38592d081","478b23e277ad488eb7fa3217fbba2709","583f9879eea3492686b7a17817870b9c","107c2637ecb44f43a5024906b22b187d","d44dbb2d6ea142dcb6120dcfdb31c4b5","882e4aec60d64898b6b38e0e3ad38892","454561a8088f46f7b3d114a5697c8f0b","f5ef722af39349e6bc6f3a1467d24540","eb821623aa244aed85d6c0b24e4cb0df","45ddd67480fc4c6385a562568c3dcdb3","505dc17e77504c54becdf4ba36fac449","51f137372a454473b572c6757be9e2e3","278e5b42378346e797f5ca8cbc82d0fb","bd8d83a1c5764893be949934f2069c8d","bc2768bf61464dbca709aebc49ab1de5","f67e5e7a9dbf4c39805268f9a40a2749","0d66231502e7451fafc32380546c72c0","70880e0dfa6642fc8393a7a809473f06","49e75a45133e47ab8ff915dd79422382","7874d5fd7b2f43409074dfc505f0ccc2","0fc928bc60de47eb9768f5b9c67f6a5e","d1ce1d879452471ba8d59ef45f21fd04","4ded81b386584718a7b069b1ed527624","619caf0d3f3242ee955500f75faec7e8","312276d9c6684272be72f7e6ed55f8e2","c535d9ab432a414f885ba7aac32681a4"]},"executionInfo":{"elapsed":8921,"status":"ok","timestamp":1724661855170,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"AtJOqENSIA9-","outputId":"6c19c77f-1018-473b-ec35-ff48573f5746"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\4호실-8\\.cache\\huggingface\\hub\\models--monologg--kobert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# num_labels는 분류할 클래스의 수를 지정합니다.\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","model = BertForSequenceClassification.from_pretrained('monologg/kobert', num_labels=2)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1724661855170,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"f1inePou16Q5"},"outputs":[],"source":["# Dataset 클래스를 정의하여 데이터를 모델에 맞게 전처리합니다.\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=128):\n","        self.texts = texts                                          # 전처리된 텍스트 데이터 리스트\n","        self.labels = labels                                        # 라벨 데이터 리스트\n","        self.tokenizer = tokenizer                                  # KoBERT 토큰나이저\n","        self.max_len = max_len                                      # 최대 토큰 길이 (128로 설정)\n","\n","    def __len__(self):\n","        return len(self.texts)                                      # 데이터셋의 크기를 반환\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]                                      # 주어진 인덱스에 해당하는 텍스트 가져오기\n","        label = self.labels[idx]                                    # 주어진 인덱스에 해당하는 라벨 가져오기\n","\n","        # 텍스트를 KoBERT 토크나이저로 인토딩하여 입력 데이터로 변환\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,                                # 특별 토큰([CLS], [SEP]) 추가\n","            max_length=self.max_len,                                # 최대 토큰 길이만큼 패딩 또는 자르기\n","            return_token_type_ids=False,                            # token_type_ids 반환하지 않음\n","            padding='max_length',                                   # max_length만큼 패딩 적용\n","            truncation=True,                                        # max_length를 초과하는 부분을 잘라냄\n","            return_attention_mask=True,                             # 어텐션 마스크 반환 (패딩된 부분은 0, 나머지는 1)\n","            return_tensors='pt',                                    # PyTorch 텐서로 변환\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),           # 인코딩된 입력 ID 텐서\n","            'attention_mask': encoding['attention_mask'].flatten(), # 어텐션 마스크 텐서\n","            'labels': torch.tensor(label, dtype=torch.long)         # 라벨 텐서 (정수형)\n","        }\n","\n","# 평가지표를 계산하는 함수 정의\n","def compute_metrics(eval_pred):                                      # 모델의 예측값과 실제 라벨을 받아 다양한 평가지표를 계산\n","    logits, labels = eval_pred                                       # eval_pred는 (logits, labels)의 튜플, 이를 분리\n","\n","    if isinstance(logits, np.ndarray):                               # logits이 numpy.ndarray 타입인 경우\n","        logits = torch.tensor(logits)                                # PyTorch 텐서로 변환하여 일관성 유지\n","\n","    predictions = torch.argmax(logits, dim=1)                        # logits에서 argmax를 사용하여 예측 클래스 인덱스를 얻음\n","\n","    acc = accuracy_score(labels, predictions.numpy())                # 실제 라벨과 예측값을 비교하여 정확도(accuracy) 계산\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(      # weighted 평균을 사용하여 precision, recall, f1-score 계산\n","        labels, predictions.numpy(), average='weighted'\n","    )\n","\n","    return {                                                         # 계산된 정확도, F1-score, precision, recall을 딕셔너리로 반환\n","        'accuracy': acc,                                             # 모델의 정확도\n","        'f1': f1,                                                    # F1-score\n","        'precision': precision,                                      # 정밀도\n","        'recall': recall                                             # 재현율\n","    }\n","\n","# 가중치를 반영한 손실 계산 함수 정의\n","def compute_loss(model, inputs, return_outputs=False):               # 손실을 계산하고 선택적으로 출력도 반환\n","    labels = inputs.get(\"labels\")                                    # 입력 데이터에서 실제 라벨을 가져옴\n","    outputs = model(**inputs)                                        # 모델에 입력 데이터를 전달하여 예측값을 계산\n","    logits = outputs.get(\"logits\")                                   # 모델의 예측 결과에서 logits(출력값)을 추출\n","\n","    loss = F.cross_entropy(logits, labels, weight=class_weights)     # 크로스 엔트로피 손실 계산, 클래스별 가중치 적용\n","\n","    return (loss, outputs) if return_outputs else loss               # return_outputs에 따라 손실과 출력 반환 여부 결정\n","\n","# 커스터마이징된 Trainer 클래스 정의\n","class CustomTrainer(Trainer):\n","    \"\"\"\n","    Trainer 클래스를 상속받아 손실 함수 계산을 커스터마이즈한 클래스입니다.\n","    주로 클래스 가중치를 적용하여 불균형한 데이터셋에서 모델 성능을 향상시키는 데 사용됩니다.\n","    \"\"\"\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        \"\"\"\n","        모델의 손실을 계산하는 메서드를 오버라이드합니다.\n","\n","        이 메서드는 모델의 예측 결과와 실제 라벨을 비교하여 손실을 계산합니다.\n","        클래스별 가중치를 적용하여 손실을 계산하며, 필요에 따라 모델 출력을 함께 반환할 수 있습니다.\n","\n","        Args:\n","            model (PreTrainedModel): 훈련할 모델 객체\n","            inputs (dict): 모델에 입력으로 전달될 데이터. 'labels'와 같은 필드를 포함해야 함\n","            return_outputs (bool, optional): 손실과 함께 모델 출력을 반환할지 여부를 결정하는 플래그. 기본값은 False\n","\n","        Returns:\n","            loss (torch.Tensor): 계산된 손실 값\n","            outputs (ModelOutput, optional): 모델의 출력값 (return_outputs=True인 경우)\n","        \"\"\"\n","\n","        # 입력 데이터에서 실제 라벨을 추출\n","        labels = inputs.get(\"labels\")\n","\n","        # 모델에 입력 데이터를 전달하여 예측값을 계산\n","        outputs = model(**inputs)\n","\n","        # 모델의 예측 결과에서 logits(출력값)을 추출\n","        logits = outputs.get(\"logits\")\n","\n","        # logits이 위치한 디바이스 (GPU 또는 CPU)에서 클래스 가중치를 이동\n","        device = logits.device\n","        weight = class_weights.to(device)\n","\n","        # 크로스 엔트로피 손실을 계산하고 클래스별 가중치를 적용\n","        loss = F.cross_entropy(logits, labels, weight=weight)\n","\n","        # return_outputs가 True일 경우 손실과 모델 출력을 함께 반환\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1724661861447,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"dQRunaHBIT5n"},"outputs":[],"source":["# 전처리된 텍스트와 라벨로 학습 및 평가 데이터셋 인스턴스 생성\n","train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_texts   = train_df['cleaned'].tolist()\n","train_labels  = label_encoder.fit_transform(train_df['Outcome'])\n","\n","eval_texts    = eval_df['cleaned'].tolist()\n","eval_labels   = label_encoder.transform(eval_df['Outcome'])\n","\n","train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n","eval_dataset  = TextDataset(eval_texts, eval_labels, tokenizer)\n","\n","# 클래스 가중치 계산\n","class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=train_labels)\n","class_weights = torch.tensor(class_weights, dtype=torch.float)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724661865906,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"S-JmUqZSIWom","outputId":"c9648427-f0cf-4f2c-cff5-f3f3e94926ee"},"outputs":[],"source":["# 학습 파라미터 설정\n","training_args = TrainingArguments(\n","    output_dir                 = '.',                                # 학습 결과가 저장될 디렉토리\n","    num_train_epochs           =3,                                   # 학습을 반복할 에폭 수\n","    per_device_train_batch_size=16,                                  # 학습 시 배치 크기\n","    per_device_eval_batch_size =16,                                  # 평가 시 배치 크기\n","    warmup_steps               =500,                                 # 학습 초기 단계에서 학습률을 서서히 증가하는 단계 수\n","    weight_decay               =0.01,                                # 가중치 감쇠 (L2 정규화) 비율\n","    logging_dir                ='.',                                 # 학습 로그가 저장될 디렉토리\n","    logging_steps              =10,                                  # 몇 스텝마다 로그를 남길지 설정\n","    evaluation_strategy        ='steps',                             # 평가 전략 (학습 중 주기적으로 평가)\n","    save_total_limit           =2                                    # 저장할 체크포인트 파일의 개수를 제한\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724661867319,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"8rjq5NZmX1f0"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\myenv\\Lib\\site-packages\\accelerate\\accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n","  warnings.warn(\n"]}],"source":["# Trainer 클래스 설정\n","# Trainer는 학습을 쉽게 관리할 수 있게 해주는 Hugging Face의 유틸리티 클래스\n","trainer = Trainer(\n","    model          = model,\n","    args           = training_args,\n","    train_dataset  = train_dataset,\n","    eval_dataset   = eval_dataset,\n","    compute_metrics= compute_metrics,\n","    # callbacks    = [ProgressCallback]\n",")\n","\n","#trainer.train()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1724662467382,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"Jay-VkzZrV_g","outputId":"108bd25e-cc6f-4f65-a030-c4c2155c8676"},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]}],"source":["# 하이퍼 파라미터 그리드 정의\n","learning_rates = [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]\n","batch_sizes    = [4, 8, 16]\n","epochs         = list(range(2, 20, 5))\n","\n","train_losses = []\n","eval_losses = []\n","best_accuracy = 0.0\n","best_model_dir = None\n","param_grid = list(itertools.product(learning_rates, batch_sizes, epochs))\n","print(len(epochs))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# 손실 값을 저장할 리스트 초기화\n","train_losses = []\n","eval_losses = []\n","best_accuracy = 0.0\n","best_model_dir = None\n","\n","def check_overfitting_or_underfitting(train_losses, eval_losses):\n","    if len(train_losses) > 1 and len(eval_losses) > 1:\n","        # 가장 최근의 손실 값\n","        last_train_loss = train_losses[-1]\n","        last_eval_loss = eval_losses[-1]\n","\n","        # 초기 손실 값\n","        initial_train_loss = train_losses[0]\n","        initial_eval_loss = eval_losses[0]\n","\n","        # 손실 감소 추세 계산\n","        train_loss_decrease = initial_train_loss - last_train_loss\n","        eval_loss_increase = last_eval_loss - initial_eval_loss\n","\n","        # 과적합 및 과소적합 조건\n","        if last_train_loss < last_eval_loss and eval_loss_increase > 0:\n","            return \"overfitting\"\n","        elif last_train_loss >= last_eval_loss and train_loss_decrease < 0.01:\n","            return \"underfitting\"\n","        else:\n","            return \"ok\"\n","    else:\n","        return \"not_enough_data\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"tQZSUFsP4bBF","outputId":"d5af5aa8-a95e-4077-98c4-6642490edfba"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rFind Best Param:   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Testing: Learning Rate=1e-05, Batch_Size=8, Epochs=2\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2380/2380 05:35, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.528200</td>\n","      <td>0.533970</td>\n","      <td>0.665126</td>\n","      <td>0.657590</td>\n","      <td>0.679981</td>\n","      <td>0.665126</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.477700</td>\n","      <td>0.523617</td>\n","      <td>0.697899</td>\n","      <td>0.666948</td>\n","      <td>0.811325</td>\n","      <td>0.697899</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='298' max='298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [298/298 00:12]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\rFind Best Param:  20%|██        | 1/5 [05:48<23:14, 348.72s/it]"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6978991596638655 - Status: not_enough_data\n","Testing: Learning Rate=2e-05, Batch_Size=8, Epochs=2\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2380/2380 05:36, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.526900</td>\n","      <td>0.533217</td>\n","      <td>0.677311</td>\n","      <td>0.663257</td>\n","      <td>0.711147</td>\n","      <td>0.677311</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.482300</td>\n","      <td>0.523375</td>\n","      <td>0.689496</td>\n","      <td>0.668770</td>\n","      <td>0.750360</td>\n","      <td>0.689496</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='102' max='298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [102/298 00:04 < 00:08, 22.90 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# 학습 과정에서 손실 값을 추적\n","for lr, batch_size, epoch in tqdm(param_grid, desc=\"Find Best Param\"):\n","    print(f\"Testing: Learning Rate={lr}, Batch_Size={batch_size}, Epochs={epoch}\")\n","\n","    training_args = TrainingArguments(\n","        output_dir                 ='./results',\n","        num_train_epochs           = epoch,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size =batch_size,\n","        warmup_steps               =500,\n","        weight_decay               =0.01,\n","        logging_dir                ='.',\n","        logging_steps              =10,\n","        evaluation_strategy        ='epoch',\n","        learning_rate              =lr\n","    )\n","\n","    # Trainer 설정\n","    trainer = Trainer(\n","        model                      =model,\n","        args                       =training_args,\n","        train_dataset              =train_dataset,\n","        eval_dataset               =eval_dataset,\n","        compute_metrics            =compute_metrics\n","    )\n","\n","    # 모델 학습\n","    train_result = trainer.train()\n","    train_losses.append(train_result.training_loss)\n","\n","    # 모델 평가\n","    eval_results = trainer.evaluate()\n","    eval_losses.append(eval_results['eval_loss'])\n","\n","    # 과적합 및 과소적합 여부 확인\n","    fitting_status = check_overfitting_or_underfitting(train_losses, eval_losses)\n","\n","    if fitting_status == \"ok\":\n","        if eval_results['eval_accuracy'] > best_accuracy:\n","            best_accuracy = eval_results['eval_accuracy']\n","            best_params = (lr, batch_size, epoch)\n","\n","            # 최적의 모델 저장\n","            best_model_dir = './best_model'\n","            trainer.save_model(best_model_dir)\n","\n","    print(f\"Accuracy: {eval_results['eval_accuracy']} - Status: {fitting_status}\")\n","\n","# 최적의 파라미터 정보 출력\n","if best_model_dir:\n","    print(f\"Best Params: Learning Rate={best_params[0]}, Batch_size={best_params[1]}, Epochs={best_params[2]}\")\n","    print(f\"Best Model saved in directory: {best_model_dir}\")\n","else:\n","    print(\"No suitable model found that is not overfitted or underfitted.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1724662438274,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"dDkw0w1MdVPH"},"outputs":[],"source":["# 최종 모델 평가\n","final_eval_results = trainer.evaluate()\n","\n","# 평가 데이터셋에 대한 예측 수행\n","eval_predictions = trainer.predict(eval_dataset)\n","y_pred = np.argmax(eval_predictions.predictions, axis=1)\n","y_true = eval_labels\n","\n","# classification_report를 계산하고 딕셔너리로 변환\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","\n","# 딕셔너리를 pandas 데이터프레임으로 변환\n","report_df = pd.DataFrame(report_dict).transpose()\n","\n","# 데이터프레임을 주피터 노트북에서 보기 좋게 출력\n","styled_report = report_df.style.format(\"{:.2f}\").background_gradient(cmap='Blues')\n","\n","# 최종 평가 결과와 스타일링된 classification_report 출력\n","print(f\"Final Accuracy: {final_eval_results['eval_accuracy']}\")\n","styled_report"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1724662438274,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"QOJC6NvCwDgo"},"outputs":[],"source":["# 예측값 계산\n","predictions, labels, _ = trainer.predict(eval_dataset)\n","predictions = torch.argmax(torch.tensor(predictions), dim=1)\n","\n","# 혼동행렬 계산 및 시각화\n","cm = confusion_matrix(labels, predictions)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1724662438274,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"SqJL2e_HYp8t"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# 라벨 인코더 생성 및 라벨 인코딩\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(df['Outcome'])\n","\n","# 각 라벨이 어떻게 인코딩되었는지 확인\n","label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n","print(\"Label Mapping:\", label_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1724662438274,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"ziNWQMgbYrcU"},"outputs":[],"source":["# 라벨 인덱스와 실제 라벨명을 매핑한 딕셔너리\n","label_map = {0: '악재', 1: '호재'}\n","\n","# 텍스트를 입력 받아 예측하는 함수 정의\n","def predict_text(text, model, tokenizer, max_len=128):\n","    encoding = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens   =True,\n","        max_length           =max_len,\n","        return_token_type_ids=False,\n","        padding              ='max_length',\n","        truncation           =True,\n","        return_attention_mask=True,\n","        return_tensors       ='pt',\n","    )\n","    input_ids      = encoding['input_ids']\n","    attention_mask = encoding['attention_mask']\n","\n","    with torch.no_grad():\n","        outputs    = model(input_ids, attention_mask=attention_mask)\n","\n","    logits     = outputs.logits\n","    prediction = torch.argmax(logits, dim=-1)\n","\n","    return prediction.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1724662438274,"user":{"displayName":"코드랩","userId":"09993968867432019708"},"user_tz":-540},"id":"FtVflcqfYses"},"outputs":[],"source":["# 테스트할 텍스트 입력\n","text_to_predict = '''[서울와이어 천성윤 기자] 삼성전자 최대 노조인 전국삼성전자노동조합(삼성노조)이 29일 파업을 선언했다. 삼성전자에서 파업은 창사 이래 처음이다.\n","\n","삼성노조는 이날 서울 서초구 삼성전자 서초사옥 앞에서 기자회견을 열고 “노동자들을 무시하는 사측의 태도에 파업을 선언한다”고 밝혔다.\n","\n","삼성노조의 파업 선언은 전날 올해 임금협상을 위한 교섭에서 사측과 이견이 좁혀지지 않으며 파행한 지 하루만에 이뤄졌다. 전날 교섭에서 노사 양측은 사측 위원 2명의 교섭 참여를 놓고 갈등을 빚었다. 이 문제 때문에 정작 핵심인 임금협상 관련 중요 내용은 오가지도 못한 것으로 알려졌다.\n","\n","삼성노조는 “사측이 교섭에 아무런 안건도 준비하지 않고 나왔다”며 파업 선언에 이르기까지의 책임을 사측에 돌렸다.\n","\n","현재 삼성노조 조합원 수는 2만8000여명으로 삼성전자 전체 직원(약 12만5000명)의 22% 수준이다. 이들이 파업에 돌입함으로서 실적 개선을 이어가야 하는 삼성전자는 큰 타격을 입을 것으로 예상된다.\n","\n","삼성전자는 지난해 반도체 업황 부진으로 디바이스솔루션(DS) 부문에서 14조8800억원의 적자를 기록했다. 올해 1분기는 매출 71조9200억원, 영업이익 6조6100억원으로 상승세에 올라탔다.\n","\n","삼성노조는 즉각적인 총파업에 나서는 대신 연차 소진 등의 방식으로 단체행동을 이어갈 예정이다. 삼성노조 집행부는 조합원들에게 오는 6월 7일 하루 연차를 소진하라는 지침을 전달했다.\n","\n","또 이날부터 서초사옥 앞에서 버스 숙박 농성을 진행한다. 삼성노조 측은 “아직은 소극적인 파업으로 볼 수 있지만, 단계를 밟아나가겠다”면서 “총파업까지 갈 수 있고, 파업이 실패할 수도 있지만 1호 파업 행동 자체가 의미 있다”고 밝혔다.\n","\n","출처 : 서울와이어(http://www.seoulwire.com)'''\n","\n","# 예측\n","predicted_label_index = predict_text(text_to_predict, model, tokenizer)\n","\n","# 예측 결과 출력\n","predicted_label = label_map[predicted_label_index]\n","print(f\"Predicted Label: {predicted_label}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOsS4NjstLy+FqF5/xMMhi4","gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0d66231502e7451fafc32380546c72c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fc928bc60de47eb9768f5b9c67f6a5e","placeholder":"​","style":"IPY_MODEL_d1ce1d879452471ba8d59ef45f21fd04","value":"model.safetensors: 100%"}},"0fc928bc60de47eb9768f5b9c67f6a5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107c2637ecb44f43a5024906b22b187d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11a3d0c57ac74fc788e3e65b6dc1e782":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1273e99a6766423ba55104faad8d40eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_583f9879eea3492686b7a17817870b9c","placeholder":"​","style":"IPY_MODEL_107c2637ecb44f43a5024906b22b187d","value":" 77.8k/77.8k [00:00&lt;00:00, 1.07MB/s]"}},"20a0a0c7e9434b96be783175d55d6a49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcc5832d35694f6bbd2758d3a701f6c0","IPY_MODEL_4ba4e2faeff44cffbefbbbeb0f53752f","IPY_MODEL_20d19704dfd5498f9b84becb4fb84435"],"layout":"IPY_MODEL_11a3d0c57ac74fc788e3e65b6dc1e782"}},"20d19704dfd5498f9b84becb4fb84435":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6a47693e8384857aab13e5d4ab05b0d","placeholder":"​","style":"IPY_MODEL_6679ad84b133433097b8204ae9bbaba9","value":" 263/263 [00:00&lt;00:00, 19.9kB/s]"}},"278e5b42378346e797f5ca8cbc82d0fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"312276d9c6684272be72f7e6ed55f8e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"454561a8088f46f7b3d114a5697c8f0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f137372a454473b572c6757be9e2e3","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_278e5b42378346e797f5ca8cbc82d0fb","value":426}},"45ddd67480fc4c6385a562568c3dcdb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"478b23e277ad488eb7fa3217fbba2709":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49e75a45133e47ab8ff915dd79422382":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_312276d9c6684272be72f7e6ed55f8e2","placeholder":"​","style":"IPY_MODEL_c535d9ab432a414f885ba7aac32681a4","value":" 369M/369M [00:01&lt;00:00, 221MB/s]"}},"4ba4e2faeff44cffbefbbbeb0f53752f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd3e3b636ac64743978083e04db057cc","max":263,"min":0,"orientation":"horizontal","style":"IPY_MODEL_868a7230127743f8b19825f5dab23bc9","value":263}},"4ded81b386584718a7b069b1ed527624":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505dc17e77504c54becdf4ba36fac449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51f137372a454473b572c6757be9e2e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5320d94d31bf49978cd43e9df815ccf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"583f9879eea3492686b7a17817870b9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"619caf0d3f3242ee955500f75faec7e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6679ad84b133433097b8204ae9bbaba9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6de4c8c208a5433c8e7fe8be4d3195a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70880e0dfa6642fc8393a7a809473f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ded81b386584718a7b069b1ed527624","max":368769812,"min":0,"orientation":"horizontal","style":"IPY_MODEL_619caf0d3f3242ee955500f75faec7e8","value":368769812}},"767babe894dc4b96b3ab34a7e7a7390d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce749d0b4c05449b932828e38592d081","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_478b23e277ad488eb7fa3217fbba2709","value":77779}},"7874d5fd7b2f43409074dfc505f0ccc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868a7230127743f8b19825f5dab23bc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"882e4aec60d64898b6b38e0e3ad38892":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45ddd67480fc4c6385a562568c3dcdb3","placeholder":"​","style":"IPY_MODEL_505dc17e77504c54becdf4ba36fac449","value":"config.json: 100%"}},"8a81ddbf107e480d9a8fbe6a2bfddf67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a87efcdaafe847398d8246638fc06db2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5320d94d31bf49978cd43e9df815ccf7","placeholder":"​","style":"IPY_MODEL_8a81ddbf107e480d9a8fbe6a2bfddf67","value":"vocab.txt: 100%"}},"bc2768bf61464dbca709aebc49ab1de5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd8d83a1c5764893be949934f2069c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c535d9ab432a414f885ba7aac32681a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce749d0b4c05449b932828e38592d081":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf14aaf71e0143fc8faf3b6e0e733876":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a87efcdaafe847398d8246638fc06db2","IPY_MODEL_767babe894dc4b96b3ab34a7e7a7390d","IPY_MODEL_1273e99a6766423ba55104faad8d40eb"],"layout":"IPY_MODEL_fba7a58fbd1f4c04b71adbd31526e731"}},"d1ce1d879452471ba8d59ef45f21fd04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d44dbb2d6ea142dcb6120dcfdb31c4b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_882e4aec60d64898b6b38e0e3ad38892","IPY_MODEL_454561a8088f46f7b3d114a5697c8f0b","IPY_MODEL_f5ef722af39349e6bc6f3a1467d24540"],"layout":"IPY_MODEL_eb821623aa244aed85d6c0b24e4cb0df"}},"d6a47693e8384857aab13e5d4ab05b0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcc5832d35694f6bbd2758d3a701f6c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6de4c8c208a5433c8e7fe8be4d3195a5","placeholder":"​","style":"IPY_MODEL_eddbc876d094424581a41dd333b984aa","value":"tokenizer_config.json: 100%"}},"dd3e3b636ac64743978083e04db057cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb821623aa244aed85d6c0b24e4cb0df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eddbc876d094424581a41dd333b984aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5ef722af39349e6bc6f3a1467d24540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd8d83a1c5764893be949934f2069c8d","placeholder":"​","style":"IPY_MODEL_bc2768bf61464dbca709aebc49ab1de5","value":" 426/426 [00:00&lt;00:00, 37.4kB/s]"}},"f67e5e7a9dbf4c39805268f9a40a2749":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d66231502e7451fafc32380546c72c0","IPY_MODEL_70880e0dfa6642fc8393a7a809473f06","IPY_MODEL_49e75a45133e47ab8ff915dd79422382"],"layout":"IPY_MODEL_7874d5fd7b2f43409074dfc505f0ccc2"}},"fba7a58fbd1f4c04b71adbd31526e731":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
