{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Komoran 형태소 분석기 초기화\n",
    "komoran = Komoran()\n",
    "\n",
    "# GPU 확인\n",
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)\n",
    "\n",
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 로드\n",
    "news_data = pd.read_excel('/content/drive/MyDrive/data/filtered_samsung_news_with_outcome.xlsx')\n",
    "\n",
    "# Outcome 레이블 변경\n",
    "news_data.loc[(news_data['Outcome'] == '호재'), 'Outcome'] = 0\n",
    "news_data.loc[(news_data['Outcome'] == '악재'), 'Outcome'] = 1\n",
    "\n",
    "# 데이터셋 나누기\n",
    "news_data_shuffled = news_data.sample(frac=1).reset_index(drop=True)\n",
    "train = news_data_shuffled[:10000]\n",
    "test = news_data_shuffled[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기를 이용한 전처리\n",
    "def preprocess_text(text):\n",
    "    tokens = komoran.morphs(text)  # 형태소 분석기 사용\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터 전처리\n",
    "sentences_train = [\"[CLS] \" + preprocess_text(str(s)) + \" [SEP]\" for s in train.content]\n",
    "\n",
    "# label 추출\n",
    "labels = train['Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 초기화 및 토큰화\n",
    "tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(s) for s in sentences_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 길이 설정 및 패딩\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 마스크 생성\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2000, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=2000, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels.astype(int))\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels.astype(int))\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈 설정 및 데이터 로더 생성\n",
    "batch_size = 32\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 사용하기 위해 파라미터 설정\n",
    "param_grid = {\n",
    "    'epochs': [3, 4],  # 에포크 수\n",
    "    'learning_rate': [2e-5, 3e-5],  # 학습률\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 옵티마이저 설정\n",
    "def create_model(learning_rate=2e-5, num_labels=2):\n",
    "    model = BertForSequenceClassification.from_pretrained('beomi/kcbert-base', num_labels=num_labels)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동 GridSearch\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "for epochs in param_grid['epochs']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        model, optimizer = create_model(learning_rate=learning_rate)\n",
    "        model.cuda()\n",
    "\n",
    "        total_steps = len(train_dataloader) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "        # 학습 루프\n",
    "        for epoch_i in range(epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            # 검증\n",
    "            model.eval()\n",
    "            eval_accuracy = 0\n",
    "            for batch in validation_dataloader:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "                logits = outputs.logits\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "                eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "            avg_eval_accuracy = eval_accuracy / len(validation_dataloader)\n",
    "\n",
    "            # 최적의 성능을 기록\n",
    "            if avg_eval_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_eval_accuracy\n",
    "                best_params = {'epochs': epochs, 'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameter and Accuracy\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 파라미터로 최종 모델 학습\n",
    "model, optimizer = create_model(learning_rate=best_params['learning_rate'])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 동일하게 Test data도 preprocessing\n",
    "# [CLS] + 문장 + [SEP]\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in test.content]\n",
    "\n",
    "# 라벨 데이터\n",
    "labels = test['Outcome'].values\n",
    "\n",
    "# Word 토크나이저 토큰화\n",
    "tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "# 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# 어텐션 마스크\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "# 파이토치 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels.astype(int))\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# 배치 사이즈 설정 및 데이터 설정\n",
    "batch_size = 32\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU or CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kc-Bert Model\n",
    "model = BertForSequenceClassification.from_pretrained('beomi/kcbert-base', num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "\n",
    "# Epochs\n",
    "epochs = 4\n",
    "\n",
    "# Total train step\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps= 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Model\n",
    "# Accuracy (정확도)\n",
    "def flat_accuracy(preds, labels) :\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels.flat) / len(labels_flat)\n",
    "\n",
    "# Time\n",
    "def format_time(elapsed) :\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seed\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Gradient (기울기)\n",
    "model.zero_grad()\n",
    "\n",
    "# Training\n",
    "for epoch_i in range(0, epochs) :\n",
    "    print()\n",
    "    print(f' Epoch {epoch_i+1} / {epochs}')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    # DataLoader에서 batch만큼 반복\n",
    "    for step, batch in enumerate(train_dataloader) :\n",
    "        if step % 500 == 0 and not step == 0 :\n",
    "            elapsed = format_time(time.time() - 10)\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids = None,\n",
    "                        attention_mask = b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():\n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks\n",
    "\n",
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = test_sentences(['''\n",
    "코스피 대장주 삼성전자가 개별 호재에도 불구, 시장 전반에 드리운 악재를 이기지 못하고 20일 만에 8만원선이 붕괴됐다. 이스라엘과 이란간 군사충돌, 이에 따른 안전자산 선호로 달러가 강세를 보이는데다 전일 미 연방준비제도(Fed) 파월 의장의 매파적 발언도 시장에 찬물을 끼얹는 분위기다.\n",
    "\n",
    "17일 한국거래소에 따르면, 삼성전자 주가는 전 거래일 대비 1100원(-1.38%) 떨어진 7만8900원에 마감, 종가기준 3월 28일 8만800원을 기록해 이른바 ‘8만전자’입성 20일 만에 다시 7만원 대로 무너졌다. 그 여파로 코스피도 지난 2월 6일 종가 2576.20을 기록한 이후 2달여 만에 다시 2600선 아래로 후퇴했다.\n",
    "\n",
    "지난해 부진을 면치 못했던 삼성전자는 최근 다시 수출이 기지개를 켜며 반등을 이어가는 분위기였다. 실적 개선과 더불어 현지시간 15일 미 상무부가 삼성전자에 대한 보조금으로 64억 달러(약 9조원) 지급을 결정하는 등 호재가 이어지는 상황이었다.\n",
    "\n",
    "다만 이와는 별개로 현지시간 13일 이란이 이스라엘에 군사공격을 감행해 언제 반격이 나올지 모르는 분위기다. 여기에 미 3월 소비자물가지수가 예상을 뛰어넘자 기준금리 인하 시기가 하반기로 이연되는 흐름에 따른 강달러 기조로 원/달러 환율이 16일 1400원을 터치하기도 했다. 다만 17일 환율은 전 거래일 대비 7.70원 하락한 1386.80원을 기록했다.\n",
    "\n",
    "여기에 기준금리 하락 기대에 선을 긋기라도 하듯 제롬 파월 미 연준 의장이 현지시간 16일 워싱턴DC에서 열린 한 포럼에서 “높은 인플레이션이 지속된다면 현재의 긴축적인 통화정책 수준을 필요한 만큼 길게 유지할 수 있다”며 매파적인 발언을 남겼다.\n",
    "\n",
    "하나증권 김록호 연구위원은 향후 삼성전자의 전망을 묻는 질문에 “삼성전자가 개별 이슈로 등락을 보이는 것을 본 적이 없다”며, “삼성전자는 하나의 종목이 아닌 코스피 그 자체로 봐야 한다”고 강조했다.\n",
    "\n",
    "김 연구위원은 “중동 이슈와 이에 따른 강달러, 여기에 파월 의장의 발언까지 코스피 전체가 영향을 받고 있다”며, “환율이 높다(원화 약세)는 것은 수출 의존도가 높은 한국 입장에서는 좋은 일이지만 외국인 입장에선 (주식)매도 욕구를 불러일으키는 일이어서 당분간 이러한 기조가 이어질 것”이라고 설명했다.\n",
    "\n",
    "실제 외국인들은 지난 3월 19일부터 4월 12일까지 쉼없이 삼성전자 순매수를 기록하다 15일 724억원 순매도를 보였고, 삼성전자가 급락해 8만원까지 밀린 16일 1070억원 순매수하며 다시 방향을 트는 듯 했으나, 17일 1451억원 순매도하며 주가 하락을 주도했다.\n",
    "\n",
    "하지만 이번 주가 조정을 투자 기회로 삼아야 한다는 목소리도 나온다.\n",
    "\n",
    "한국투자증권 채민숙 연구원은 17일 ‘소나기는 그치기 마련’이라는 제목의 보고서를 통해 “반도체는 내수 대비 수출 비중이 절대적으로 높고 본사와 해외법인, 고객간 거래 시 모두 달러로 결제하기 때문에 환율 상승은 메모리 반도체 기업 실적에는 긍정적”이라며, “메모리반도체 특성 상 매출원가에서 고정비가 가장 큰 부분을 차지하고 (수입을 하는) 원재료비 비중은 상대적으로 낮기 때문에 환율 상승에 따른 재료비 증가분 이상으로 매출액과 영업이익이 늘어난다”고 설명했다.\n",
    "\n",
    "이어 “일반적으로 원/달러 환율 상승기에 삼성전자와 SK하이닉스 주가는 약세였다”면서도 “환율 하나만으로 주가 방향성에 대한 판단을 내리기 어렵고, 1분기 호실적 발표와 2분기 이후 우호적인 업황 코멘트가 예상되는 실적 발표 시즌을 앞두고 있는 시점에서 환율이 단기적으로 오버슈팅한 것이라면 매크로 불확실성이 걷힐 때 섹터 내 긍정적 요인들이 더욱 부각될 수 있을 것”이라고 전망했다.\n",
    "\n",
    "출처 : 스트레이트뉴스(https://www.straightnews.co.kr)\n",
    "'''])\n",
    "print(logits)\n",
    "\n",
    "if np.argmax(logits) == 1 :\n",
    "    print(\"악재\")\n",
    "elif np.argmax(logits) == 0 :\n",
    "    print(\"호재\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# 실제 레이블과 예측 레이블을 저장할 리스트\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# 테스트 데이터셋에 대해 예측 수행\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # 예측된 레이블 저장\n",
    "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat = label_ids.flatten()\n",
    "\n",
    "    true_labels.extend(labels_flat)\n",
    "    pred_labels.extend(pred_flat)\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# 혼동 행렬 출력 및 시각화\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 정밀도, 재현율, F1 점수를 포함한 분류 보고서 출력\n",
    "report = classification_report(true_labels, pred_labels, target_names=['0', '1'])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
